# -*- coding: utf-8 -*-
"""getalldata.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dXPg66UxldPtx3ZWOhcmUg0noLz0rrtQ
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy import stats
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score, log_loss
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

import os, pickle, cv2
import seaborn as sns; sns.set()
import matplotlib.pyplot as plt
from numpy import asarray

import tensorflow
from keras import applications

from tensorflow.keras.applications.vgg16 import VGG16 
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras.preprocessing import image    

from sklearn.model_selection import train_test_split

from tensorflow.keras.layers import BatchNormalization
from keras.models import Sequential, load_model
from tensorflow.keras.layers import Conv2D, Activation, Flatten, Dropout, Dense
# import tensorflow
from tensorflow.keras import backend as K
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ReduceLROnPlateau, EarlyStopping
from tensorflow.keras.optimizers import RMSprop, Adagrad, Adam

"""# Please, note that this is a script that should be written as a **Class**. Due to time constraints, it makes use of local variables."""

from google.colab import drive
drive.mount('/content/drive')

import shutil
try:
  shutil.rmtree("/content/food")
except:
  pass

try:
  shutil.rmtree("/content/food_pre")
except:
  pass

os.mkdir("food")
os.mkdir("food/Train")
os.mkdir("food/Test")
os.mkdir("food/Valid")

# !unzip "/content/drive/MyDrive/foodtask/Train.zip" -d /content/food/
# !unzip "/content/drive/MyDrive/foodtask/Valid.zip" -d /content/food/
# !unzip "/content/drive/MyDrive/foodtask/Test.zip" -d /content/food/Test/

w = 80
h = 60

def getall():
  data = {}
  data_inet = {}

  metadata = {"Train/":{0:0, 1:0}, "Valid/":{0:0, 1:0}}
  for folder in ["Train/", "Valid/"]:
    data[folder] = []
    data_inet[folder] = []
    for classe in [0,1]:
      print(classe)
      dir = "/content/food/" + folder + str(classe)
      lent = 0
      for each in os.listdir(dir):
        image = cv2.imread(os.path.join(dir, each))
        
        img_inet = cv2.resize(image,(80,60))
        data_inet[folder].append(asarray(img_inet))

        gs_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        gs_image = cv2.resize(gs_image,(80,60))
        # print("gs shape : ", gs_image.shape)
        if gs_image.shape != (60,80):
          gs_image = gs_image.resize((240,320))
          print("We resized an image!!")
        lent += 1
        data[folder].append(asarray(gs_image))
      metadata[folder][classe] = lent

  y_train =  np.concatenate( (np.zeros((metadata["Train/"][0],1)), np.ones((metadata["Train/"][1],1))) )
  y_valid =  np.concatenate( (np.zeros((metadata["Valid/"][0],1)), np.ones((metadata["Valid/"][1],1))) )
  
  data_stack = {"Train/":data["Train/"],"Valid/":data["Valid/"]}
  m = len(data["Train/"])

  data_stack["Train/"] = np.stack(data_stack["Train/"], axis = 0).reshape((m, h*w))
  data_stack["Train/"] = np.concatenate((data_stack["Train/"],y_train), axis = 1 )
  # data["Train/"] = np.concatenate((data["Train/"],y_train), axis = 1 )
  print(data_stack["Train/"].shape)

  ## Valid
  m = len(data["Valid/"])
  data_stack["Valid/"] = np.stack(data_stack["Valid/"], axis = 0).reshape((m, h*w))
  data_stack["Valid/"] = np.concatenate((data_stack["Valid/"], y_valid), axis = 1)
  # data["Valid/"] = np.concatenate((data["Valid/"], y_test), axis = 1)

  data_inet["Train/"], data_inet["Valid/"] = process_inet(data_inet)

  return data, data_inet, data_stack

def process_inet(data_inet):

  data_inet["Train/"] = np.array(data_inet["Train/"])
  data_inet["Train/"] = preprocess_input(data_inet["Train/"])

  data_inet["Valid/"] = np.array(data_inet["Valid/"])
  data_inet["Valid/"] = preprocess_input(data_inet["Valid/"])

  return data_inet["Train/"], data_inet["Valid/"]

def features_vgg(data_inet):

  conv = tensorflow.keras.applications.VGG16(include_top=False, weights='imagenet')

  bottleneck_features0tr = conv.predict(data_inet["Train/"][:6404,:])
  bottleneck_features0val = conv.predict(data_inet["Valid/"][:1601,:]) 

  # ### For class 1:
  bottleneck_features1tr = conv.predict(data_inet["Train/"][6404:,:])   
  bottleneck_features1val = conv.predict(data_inet["Valid/"][1601:,:])    

  ## Training features
  bottleneck_features0tr = bottleneck_features0tr.reshape((len(data_inet["Train/"][:6404,:]),-1))
  bottleneck_features1tr = bottleneck_features1tr.reshape((len(data_inet["Train/"][6404:,:]),-1))

  # features_dataTrain = np.vstack((bottleneck_features1tr,bottleneck_features0tr))
  features_dataTrain = np.vstack((bottleneck_features0tr,bottleneck_features1tr))
  features_dataTrain.shape

  ## Validation features
  bottleneck_features0val = bottleneck_features0val.reshape((len(data_inet["Valid/"][:1601,:]),-1))
  bottleneck_features1val = bottleneck_features1val.reshape((len(data_inet["Valid/"][1601:,:]),-1))

  # features_dataVal = np.vstack((bottleneck_features1val,bottleneck_features0val))
  features_dataVal = np.vstack((bottleneck_features0val,bottleneck_features1val))
  features_dataVal.shape

  # np.save(open('featuresTrain_vgg16SVM.npy', 'wb'), features_dataTrain)
  # np.save(open('featuresValid_vgg16SVM.npy', 'wb'), features_dataVal)

  return features_dataTrain, features_dataVal